{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Space Report\n",
    "\n",
    "\n",
    "<img src=\"images/polito_logo.png\" alt=\"Polito Logo\" style=\"width: 200px;\"/>\n",
    "\n",
    "\n",
    "## Pittsburgh Bridges Data Set\n",
    "\n",
    "<img src=\"images/andy_warhol_bridge.jpg\" alt=\"Andy Warhol Bridge\" style=\"width: 200px;\"/>\n",
    "\n",
    "    Andy Warhol Bridge - Pittsburgh.\n",
    "\n",
    "Report created by Student Francesco Maria Chiarlo s253666, for A.A 2019/2020.\n",
    "\n",
    "**Abstract**:The aim of this report is to evaluate the effectiveness of distinct, different statistical learning approaches, in particular focusing on their characteristics as well as on their advantages and backwards when applied onto a relatively small dataset as the one employed within this report, that is Pittsburgh Bridgesdataset.\n",
    "\n",
    "**Key words**:Statistical Learning, Machine Learning, Bridge Design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports Section <a class=\"anchor\" id=\"imports-section\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from utils.all_imports import *;\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================== #\n",
    "# READ INPUT DATASET\n",
    "# =========================================================================== #\n",
    "\n",
    "dataset_path = 'C:\\\\Users\\\\Francesco\\Documents\\\\datasets\\\\pittsburgh_dataset'\n",
    "dataset_name = 'bridges.data.csv'\n",
    "\n",
    "TARGET_COL = 'T-OR-D'  # Target variable name\n",
    "dataset, feature_vs_values = load_brdiges_dataset(dataset_path, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_2_avoid = ['ERECTED', 'LENGTH', 'LOCATION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary about Target Variable {target_col}\n",
      "--------------------------------------------------\n",
      "2    57\n",
      "1    13\n",
      "Name: T-OR-D, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Make distinction between Target Variable and Predictors\n",
    "# --------------------------------------------------------------------------- #\n",
    "\n",
    "columns = dataset.columns  # List of all attribute names\n",
    "\n",
    "# Get Target values and map to 0s and 1s\n",
    "# y = np.array(list(map(lambda x: 0 if x == 1 else 1, dataset[TARGET_COL].values)))\n",
    "y = np.array(list(map(lambda x: -1 if x == 1 else 1, dataset[TARGET_COL].values)))\n",
    "print('Summary about Target Variable {target_col}')\n",
    "print('-' * 50)\n",
    "print(dataset[TARGET_COL].value_counts())\n",
    "\n",
    "# Get Predictors\n",
    "X = dataset.loc[:, dataset.columns != TARGET_COL].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape features matrix X, after normalizing:  (70, 11)\n"
     ]
    }
   ],
   "source": [
    "# Standardizing the features\n",
    "# --------------------------------------------------------------------------- #\n",
    "scaler_methods = ['minmax', 'standard', 'norm']\n",
    "scaler_method = 'standard'\n",
    "rescaledX = preprocessing_data_rescaling(scaler_method, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pricipal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = rescaledX.shape[1]\n",
    "pca = PCA(n_components=n_components)\n",
    "# pca = PCA(n_components=2)\n",
    "\n",
    "# X_pca = pca.fit_transform(X)\n",
    "pca = pca.fit(rescaledX)\n",
    "X_pca = pca.transform(rescaledX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative varation explained(percentage) up to given number of pcs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># PCS</th>\n",
       "      <th>Cumulative Varation Explained (percentage)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>47.738342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>75.856460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>82.615768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>88.413903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>92.661938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>95.976841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>98.432807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # PCS  Cumulative Varation Explained (percentage)\n",
       "0      2                                   47.738342\n",
       "1      5                                   75.856460\n",
       "2      6                                   82.615768\n",
       "3      7                                   88.413903\n",
       "4      8                                   92.661938\n",
       "5      9                                   95.976841\n",
       "6     10                                   98.432807"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Cumulative varation explained(percentage) up to given number of pcs:\")\n",
    "\n",
    "tmp_data = []\n",
    "principal_components = [pc for pc in '2,5,6,7,8,9,10'.split(',')]\n",
    "for _, pc in enumerate(principal_components):\n",
    "    n_components = int(pc)\n",
    "    \n",
    "    cum_var_exp_up_to_n_pcs = np.cumsum(pca.explained_variance_ratio_)[n_components-1]\n",
    "    # print(f\"Cumulative varation explained up to {n_components} pcs = {cum_var_exp_up_to_n_pcs}\")\n",
    "    # print(f\"# pcs {n_components}: {cum_var_exp_up_to_n_pcs*100:.2f}%\")\n",
    "    tmp_data.append([n_components, cum_var_exp_up_to_n_pcs * 100])\n",
    "\n",
    "tmp_df = pd.DataFrame(data=tmp_data, columns=['# PCS', 'Cumulative Varation Explained (percentage)'])\n",
    "tmp_df.head(len(tmp_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Major Pros & Cons of PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Models <a class=\"anchor\" id=\"learning-models\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to be tested for Cross-Validation Approach\n",
    "\n",
    "# estimators_list = [GaussianNB(), LogisticRegression(), KNeighborsClassifier(), SGDClassifier(), SVC(), DecisionTreeClassifier(), RandomForestClassifier()]\n",
    "estimators_list = [GaussianNB(), LogisticRegression(random_state=0), KNeighborsClassifier(), SGDClassifier(random_state=0), SVC(random_state=0), DecisionTreeClassifier(random_state=0), RandomForestClassifier(random_state=0)]\n",
    "estimators_names = ['GaussianNB', 'LogRegr', 'Knn', 'SGD', 'SVC', 'DecisionTree', 'RandomForest']\n",
    "plots_names = list(map(lambda xi: f\"{xi}_learning_curve.png\", estimators_names))\n",
    "\n",
    "pca_kernels_list = ['linear', 'poly', 'rbf', 'cosine', 'sigmoid']\n",
    "cv_list = [10, 9, 8, 7, 6, 5, 4, 3, 2]\n",
    "\n",
    "parmas_logistic_regression = {\n",
    "    'penalty': ('l1', 'l2', 'elastic', None),\n",
    "    'solver': ('newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'),\n",
    "    'fit_intercept': (True, False),\n",
    "    'tol': (1e-4, 1e-3, 1e-2),\n",
    "    'class_weight': (None, 'balanced'),\n",
    "    'C': (10.0, 1.0, .1, .01, .001, .0001),\n",
    "    # 'random_state': (0,),\n",
    "}\n",
    "\n",
    "\n",
    "parmas_knn_forest = {\n",
    "    'n_neighbors': (2,3,4,5,6,7,8,9,10),\n",
    "    'weights': ('uniform', 'distance'),\n",
    "    'metric': ('euclidean', 'minkowski', 'manhattan'),\n",
    "    'leaf_size': (5, 10, 15, 30),\n",
    "    'algorithm': ('ball_tree', 'kd_tree', 'brute'),\n",
    "    # 'random_state': (0,),\n",
    "}\n",
    "\n",
    "parameters_sgd_classifier = {\n",
    "    'loss': ('log', 'modified_huber'), # ('hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron')\n",
    "    'penalty': ('l2', 'l1', 'elasticnet'),\n",
    "    'alpha': (1e-1, 1e-2, 1e-3, 1e-4),\n",
    "    'max_iter': (50, 100, 150, 200, 500, 1000, 1500, 2000, 2500),\n",
    "    'learning_rate': ('optimal',),\n",
    "    'tol': (None, 1e-2, 1e-4, 1e-5, 1e-6)\n",
    "    # 'random_state': (0,),\n",
    "}\n",
    "\n",
    "kernel_type = 'svm-rbf-kernel'\n",
    "parameters_svm = {\n",
    "    'gamma': (0.003, 0.03, 0.05, 0.5, 0.7, 1.0, 1.5),\n",
    "    'max_iter':(1e+2, 1e+3, 2 * 1e+3, 5 * 1e+3, 1e+4, 1.5 * 1e+3),\n",
    "    # 'penalty': ('l2','l1'),\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid',],\n",
    "    'C': (1e-4, 1e-3, 1e-2, 0.1, 1.0, 10, 1e+2, 1e+3),\n",
    "    'probability': (True,), \n",
    "    # 'random_state': (0,),\n",
    "}\n",
    "\n",
    "parmas_decision_tree = {\n",
    "    'splitter': ('random', 'best'),\n",
    "    'criterion':('gini', 'entropy'),\n",
    "    'max_features': (None, 'sqrt', 'log2'),\n",
    "    'max_depth': (None, 3, 5, 7, 10,),\n",
    "    'splitter': ('best', 'random',),\n",
    "    'class_weight': (None, 'balanced'),\n",
    "    'min_samples_leaf': (1,2,3,4,5),\n",
    "    # 'random_state': (0,),\n",
    "}\n",
    "\n",
    "parmas_random_forest = {\n",
    "    'n_estimators': (3, 5, 7, 10, 30, 50, 70, 100, 150, 200),\n",
    "    'criterion':('gini', 'entropy'),\n",
    "    'bootstrap': (True, False),\n",
    "    'min_samples_leaf': (1,2,3,4,5),\n",
    "    'max_features': (None, 'sqrt', 'log2'),\n",
    "    'max_depth': (None, 3, 5, 7, 10,),\n",
    "    'class_weight': (None, 'balanced', 'balanced_subsample'),\n",
    "    # 'random_state': (0,),\n",
    "}\n",
    "\n",
    "param_grids = [parmas_logistic_regression, parmas_knn_forest, parameters_sgd_classifier, parameters_svm, parmas_decision_tree, parmas_random_forest]\n",
    "\n",
    "N_CV, N_KERNEL, N_GS = 9, 4, 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Learning Technique | Type of Learner | Type of Learning | Classification | Regression |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| *Logistic Regression* | *Linear Model* | *Supervised Learning* | *Supported* | *Not-Supported* |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components=9\n",
    "learning_curves_by_kernels(\n",
    "# learning_curves_by_components(\n",
    "    estimators_list[:], estimators_names[:],\n",
    "    rescaledX, y,\n",
    "    train_sizes=np.linspace(.1, 1.0, 10),\n",
    "    n_components=9,\n",
    "    pca_kernels_list=pca_kernels_list[0],\n",
    "    verbose=0,\n",
    "    by_pairs=True,\n",
    "    savefigs=True,\n",
    "    scoring='accuracy',\n",
    "    figs_dest=os.path.join('figures', 'learning_curve', f\"Pcs_{n_components}\"), ignore_func=True,\n",
    "    # figsize=(20,5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel PCA: Linear | LogRegr\n",
      "====================================================================================================\n",
      "ERROR: Kernel PCA: Linear | LogRegr- error message: 'HBox' object has no attribute 'head'\n",
      "Kernel PCA: Poly | LogRegr\n",
      "====================================================================================================\n",
      "ERROR: Kernel PCA: Poly | LogRegr- error message: 'HBox' object has no attribute 'head'\n",
      "Kernel PCA: Rbf | LogRegr\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "plot_dest = os.path.join(\"figures\", \"n_comp_9_analysis\", \"grid_search\")\n",
    "X = rescaledX\n",
    "\n",
    "df_gs, df_auc_gs = grid_search_all_by_n_components(\n",
    "    estimators_list=estimators_list[1], \\\n",
    "    param_grids=param_grids[0],\n",
    "    estimators_names=estimators_names[1], \\\n",
    "    X=X, y=y,\n",
    "    n_components=9,\n",
    "    random_state=0, show_plots=False, show_errors=False, verbose=1, plot_dest=plot_dest, debug_var=False)\n",
    "df_9, df_9_auc = df_gs, df_auc_gs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results obtained running *Logistic Regression Classifier* against our dataset splitted into training set and test set and adopting a different kernel trick applied to *kernel-Pca* unsupervised preprocessing method we can state that generally speaking all the methods shonw a very high *Train Accuracy Score*  which reaches in the most of the case a value greater than *90%*. However only one trial out of five, that is trial in which we adopted *Cosine Trick* we was able to account for *74%* of accuracy than the other cases where instead we do not reach a *train accuracy score* greater than *50%*. So, we can end up saying that the other models either overfit to the *train set* and wasn't able to generalize well on *test set*, or the fact that our dataset is not a balanced one leads to models and estimators that were able to correctly predict one among the two classes and more specifically, the models seems to recognize better the *class 0*, that is *Deck Bridges* than *class 1*, that is *Through Bridges*. In other words, usually working with unbalanced dataset we expect that the most frequent classes or most numerous classes were advantaged against the less numerous, but here emploping Logisti Regression Classifier we obtained models that were more able to correctly classify the less numerous class and to worngly predict the more numerous class. More precisely:\n",
    "- speaking about __Linear kernel Pca based Logisti Classifier__, we can notice that such a model exploiting a default threshold of *.5* reaches a poor test accuracy score of just *41%* with respect to a train accuracy score of *97%*. The model indeed overfits to the overall train set and tends to better predict the less numerous class, so the model gains weight parameters suitable to identify class 0 samples. Looking at *recall and precision scores*, the model was really precise when predicting class 1 examples and was able to correcly predict labels for class 0, so maximzes recall of negative class. But we cannot say it is also precise when predicting class 0 this means that it wrongly inferes the true label for positive class. Lastly the model obtained high and low weighted average precision and recall, such that weigthed *F1-score* was low as well. Speaking about *Roc curve and Auc Score*, we can unbderstand that the model obtains a intermediate Auc score, of *.64* than the Random Classifier, and the relationship between *FPR and TPR* is linear most of the time changing the threshold value for classification.\n",
    "- observing __Polynomial kernel Pca based Logisti Classifier__, we can notice that such a model exploiting a default threshold of *.5* reaches even a lower test accuracy of *32%* than a still high train accuracy of *91%*. So also here for this trial the resulting model overfit to the train set and becaus of both lower accuracy scores we can can state that the model wrongly predicts a larger number of samples from class 1. In fact the model's precision and recall of class 0 and class 1 lowered than the values seens for the previous trial, while the precision and recall of class 1 and class 0 still remain the same, so this model preidcts with high precision samples from class 1 but with great uncertainty about class 0, even if most of the sample from such a classes were correctly labeled. Looking at *Roc Curve and Auc Score* we can observe that the best found model with this configuration indeed is going slightly bettere than random classifier, in fact has a auc score equals just to *.59* and the *TPR and FPR* behaviors is that them grows linearly while modifying the default threshold value most of the time.\n",
    "- review __Rbf kernel Pca based Logisti Classifier__, we can stricly and briefly saying that as the two preivous models also here discussing this estimator performance we do not obtain satisfying results in fact the model behaves more or less as the first reviewed, and more precisely the model obtained a slighlty better accuracy on test set of *.47* and a weighted F1-Score of *.5*, that allow for a Auc score that reaches a value of *.68* However also this model overfit to the train set with an accuracy score of *92%*, and is more able to correcly predict class 1 instances with high precision and class 0 instances with more uncertainty, even if has a high recall related to class 0.\n",
    "- __Cosine kernel Pca based Logisti Classifier__ results to be the best solution found while performing grid search algorithm for Logisti Regression method, when it is fixed a defualt threshold of *.5* for classification. The rationale is that this trial retrieves a model that does not overfit to the train set, since test set accuracy is *74%*, just nearly 20 percent points than train accuracy score of *92%*. Moreover, we obtain high values for both *averaged precions, recalla and F1-Score metrics*, where the latter more precisely was even gretaer than test accuracy score, reachiung a value of *77%*. However, this model as others is less precise when predicting labels for class 0, than when inferring class 1 lables, this is mostly due to the fact that the dataset is not balanced. So we still remain more confident and precise when predicting class labels for class 1 examples. Looking at Roc Curve and Auc Score, we can say that for this model we have a curve which is able to account for up to *77%* of auc, and that this model works fine for many thresholds, in particular we can imagine to lower down a little bit the default threshold so that we can improve *TPR* reducing slightly *FPR* scores.\n",
    "- lastly, also __Sigmoid kernel Pca based Logisti Classifier__ as other previous trials except the one represented by the moedl trained fixing Cosine Trick as kernel Pca method, gains poor and lower performance, due to overfit issue and as other more or less same low performance models generally speaking obtains high and low weighted average precision and recall scores, meaning that while the few instances predicted as belonging to class 1 was done with high precision instead of samples from class 0 which was prediceted with high uncertainty, even if most of the time the model correctly predicts instances that indeed belongs to class 0. The Roc Curve and Auc Score of *62%* show that also this run leads to a model which TPR and FPR are most of the time growing linearly across the thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_widget_list_df([df_gs, df_auc_gs]) #print(df_gs); print(df_auc_gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the table dispalyed just above that shows the details about the selected values for hyper-parameters specified during grid search, in the different situations accordingly to the fixed kernel-trick for kernel Pca unsupervised method we can state that, referring to the first two columns of *Train and Test Accuracy*, we can recognize which trials lead to more overfit results such as for *Linear, Polynomial, Rbf, and Sigmoid Tricks* or less overfit solution such as in the case of *Cosine Trick*. Speaking about the hyper-parameters, we can say what follows:\n",
    "- speaking about the *hyper-param C*, that is inverse of regularization strength where smaller values specify stronger regularization, we observe that except the Cosine kernel trick case all other kernel-Pca tricks adopted have preferred to exploit a very low value for *C parameter* equals to *0.001* and accounts for a very strtong regularization, but such a choice does not lead to models that obtained a high generalization capability, instead the *Cosine based kernel-Pca* model opted for a default value for such a parameter.\n",
    "- instead referring to *class_weight parameter*, we knwo that it can be set with balanced strategy which stends for a strategy where values of y to automatically adjust weights inversely proportional to class frequencies in the input data as *n_samples / (n_classes * np.bincount(y))*, we have been surprised that all the method that obtained worst performance choose a balanced strategy than the best model which was fine even with a default strategy that does not require to use a balanced mode.\n",
    "- instead *fit_intercept parameter* refers to the fact that we specify if a constant (a.k.a. bias or intercept) should be added to the decision function, and allows for modeling a certain behavior and a certain response different from zero even when the input sample is mostly made of zero components, we can understand that in all the cases the models obtained best results enabling such strategy and so the models are fitted taking into account also a intercept weight or parameter, increasing model complexity.\n",
    "- model's *penalty parameter* allows to specify the norm used in the penalization, among the folowing list of possible choices *l1, l2, elasticnet*. In all the models the best choice was for *l2 regularization*, this means that all the models opted for a kind of regularization that do not consider at all the *l1 normalization* as a regularization technique, so we avoid to obtain models that instead may lead weights to zero values, in other words sparse models.\n",
    "- model's *solver parameter* which is the algorithm to use in the optimization problem. It is curios to notice that almost all the models except cosine based kernel-Pca which adopted *liblinear* solver. What we can understand is that for all the overfitted models the choice of *sag* solver does not lead to significant results in term of performance, and we can say instead that we correctly except that for such a small dataset a *liblinear* choice is the most suitable and the best model found here is coherent with such a suggestion from theory field.\n",
    "- lastly, looking at *tol parameter*, which stends for tolerance for stopping criteria, we can clearly see that the first two models adopted a lowe tolerance value instead the last three preferred a lower value of tolerance, so the first two methods accordingly with the kind of kernel trick technique adopted for kernel-Pca seem to go well when a tolerance value is not so small as the last three methods, furthermore the first two methods request less time than the last three because of the lareger tolerance set for training convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvements and Conclusions <a class=\"anchor\" id=\"Improvements-and-conclusions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References section  <a class=\"anchor\" id=\"references\"></a>\n",
    "### Main References\n",
    "- Data Domain Information part:\n",
    "    - (Deck) https://en.wikipedia.org/wiki/Deck_(bridge)\n",
    "    - (Cantilever bridge) https://en.wikipedia.org/wiki/Cantilever_bridge\n",
    "    - (Arch bridge) https://en.wikipedia.org/wiki/Deck_(bridge)\n",
    "- Machine Learning part:\n",
    "    - (Theory Book) https://jakevdp.github.io/PythonDataScienceHandbook/\n",
    "    - (Feature Extraction: PCA) https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "    - (Linear Model: Logistic Regression) https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "    - (Neighbor-based Learning: Knn) https://scikit-learn.org/stable/modules/neighbors.html\n",
    "    - (Stochastc Learning: SGD Classifier) https://scikit-learn.org/stable/modules/sgd.html#sgd\n",
    "    - (Discriminative Model: SVM) https://scikit-learn.org/stable/modules/svm.html\n",
    "    - (Non-Parametric Learning: Decsion Trees) https://scikit-learn.org/stable/modules/tree.html#tree\n",
    "    - (Ensemble, Non-Parametric Learning: RandomForest) https://scikit-learn.org/stable/modules/ensemble.html#forest\n",
    "- Metrics:\n",
    "    - (F1-Accuracy-Precision-Recall) https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c\n",
    "- Statistics:\n",
    "    - (Correlation and dependence) https://en.wikipedia.org/wiki/Correlation_and_dependence\n",
    "    - (KDE) https://jakevdp.github.io/blog/2013/12/01/kernel-density-estimation/\n",
    "- Chart part:\n",
    "    - (Seaborn Charts) https://acadgild.com/blog/data-visualization-using-matplotlib-and-seaborn\n",
    "- Third Party Library:\n",
    "    - (sklearn) https://scikit-learn.org/stable/index.html\n",
    "    - (statsmodels) https://www.statsmodels.org/stable/index.html#\n",
    "\n",
    "    \n",
    "### Others References\n",
    "- Plots:\n",
    "    - (Python Plot) https://www.datacamp.com/community/tutorials/matplotlib-tutorial-python?utm_source=adwords_ppc&utm_campaignid=898687156&utm_adgroupid=48947256715&utm_device=c&utm_keyword=&utm_matchtype=b&utm_network=g&utm_adpostion=&utm_creative=255798340456&utm_targetid=aud-299261629574:dsa-473406587955&utm_loc_interest_ms=&utm_loc_physical_ms=1008025&gclid=Cj0KCQjw-_j1BRDkARIsAJcfmTFu4LAUDhRGK2D027PHiqIPSlxK3ud87Ek_lwOu8rt8A8YLrjFiHqsaAoLDEALw_wcB\n",
    "- Markdown Math part:\n",
    "    - (Math Symbols Latex) https://oeis.org/wiki/List_of_LaTeX_mathematical_symbols\n",
    "    - (Tutorial 1) https://share.cocalc.com/share/b4a30ed038ee41d868dad094193ac462ccd228e2/Homework%20/HW%201.2%20-%20Markdown%20and%20LaTeX%20Cheatsheet.ipynb?viewer=share\n",
    "    - (Tutorial 2) https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Typesetting%20Equations.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
