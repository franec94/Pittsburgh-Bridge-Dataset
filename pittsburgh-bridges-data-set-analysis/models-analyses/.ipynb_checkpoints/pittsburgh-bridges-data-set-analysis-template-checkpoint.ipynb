{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pittsburgh Bridges Data Set\n",
    "\n",
    "- https://www.datacamp.com/community/tutorials/categorical-datas\n",
    "- http://cmdlinetips.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.display_utils import display_heatmap\n",
    "from utils.display_utils import show_frequency_distribution_predictors\n",
    "from utils.display_utils import show_categorical_predictor_values\n",
    "from utils.display_utils import  show_cum_variance_vs_components\n",
    "\n",
    "from utils.preprocessing_utils import preprocess_categorical_variables\n",
    "from utils.preprocessing_utils import  preprocessing_data_rescaling\n",
    "\n",
    "from utils.training_utils import sgd_classifier_grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "%matplotlib inline\n",
    "# Matplotlib pyplot provides plotting API\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import chart_studio.plotly.plotly as py\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/franec94/Documents/datasets/datasets_folders/pittsburgh-bridges-data-set'\n",
    "dataset_name = 'bridges.data.csv'\n",
    "\n",
    "# column_names = ['IDENTIF', 'RIVER', 'LOCATION', 'ERECTED', 'PURPOSE', 'LENGTH', 'LANES', 'CLEAR-G', 'T-OR-D', 'MATERIAL', 'SPAN', 'REL-L', 'TYPE']\n",
    "column_names = ['RIVER', 'LOCATION', 'ERECTED', 'PURPOSE', 'LENGTH', 'LANES', 'CLEAR-G', 'T-OR-D', 'MATERIAL', 'SPAN', 'REL-L', 'TYPE']\n",
    "dataset = pd.read_csv('{}/{}'.format(dataset_path, dataset_name), names=column_names, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Dataset shape: {}'.format(dataset.shape))\n",
    "# print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'M', 'O', 'Y']\n",
      "['AQUEDUCT', 'HIGHWAY', 'RR', 'WALK']\n",
      "['?', 'G', 'N']\n",
      "['?', 'DECK', 'THROUGH']\n",
      "['?', 'IRON', 'STEEL', 'WOOD']\n",
      "['?', 'LONG', 'MEDIUM', 'SHORT']\n",
      "['?', 'F', 'S', 'S-F']\n",
      "['?', 'ARCH', 'CANTILEV', 'CONT-T', 'NIL', 'SIMPLE-T', 'SUSPEN', 'WOOD']\n"
     ]
    }
   ],
   "source": [
    "columns_2_avoid = ['ERECTED', 'LENGTH', 'LOCATION', 'LANES']\n",
    "list_columns_2_fix = show_categorical_predictor_values(dataset, columns_2_avoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'M', 'O', 'Y']\n",
      "['AQUEDUCT', 'HIGHWAY', 'RR']\n",
      "['G', 'N']\n",
      "['DECK', 'THROUGH']\n",
      "['IRON', 'STEEL', 'WOOD']\n",
      "['LONG', 'MEDIUM', 'SHORT']\n",
      "['F', 'S', 'S-F']\n",
      "['ARCH', 'CANTILEV', 'CONT-T', 'SIMPLE-T', 'SUSPEN', 'WOOD']\n"
     ]
    }
   ],
   "source": [
    "for _, predictor in enumerate(list_columns_2_fix):\n",
    "    dataset = dataset[dataset[predictor] != '?']\n",
    "_ = show_categorical_predictor_values(dataset, columns_2_avoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 88 entries, E1 to E90\n",
      "Data columns (total 12 columns):\n",
      "RIVER       88 non-null int64\n",
      "LOCATION    88 non-null object\n",
      "ERECTED     88 non-null int64\n",
      "PURPOSE     88 non-null int64\n",
      "LENGTH      88 non-null object\n",
      "LANES       88 non-null object\n",
      "CLEAR-G     88 non-null int64\n",
      "T-OR-D      88 non-null int64\n",
      "MATERIAL    88 non-null int64\n",
      "SPAN        88 non-null int64\n",
      "REL-L       88 non-null int64\n",
      "TYPE        88 non-null int64\n",
      "dtypes: int64(9), object(3)\n",
      "memory usage: 8.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "preprocess_categorical_variables(dataset, columns_2_avoid)\n",
    "\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.boxplot('RIVER','TYPE',rot = 30,figsize=(5,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RIVER</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>ERECTED</th>\n",
       "      <th>PURPOSE</th>\n",
       "      <th>LENGTH</th>\n",
       "      <th>LANES</th>\n",
       "      <th>CLEAR-G</th>\n",
       "      <th>T-OR-D</th>\n",
       "      <th>MATERIAL</th>\n",
       "      <th>SPAN</th>\n",
       "      <th>REL-L</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>E1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1818</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E2</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1819</td>\n",
       "      <td>2</td>\n",
       "      <td>1037</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E5</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1837</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E7</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1840</td>\n",
       "      <td>2</td>\n",
       "      <td>990</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E8</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1844</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RIVER LOCATION  ERECTED  PURPOSE LENGTH LANES  CLEAR-G  T-OR-D  MATERIAL  \\\n",
       "E1      2        3     1818        2      ?     2        2       2         3   \n",
       "E2      1       25     1819        2   1037     2        2       2         3   \n",
       "E5      1       29     1837        2   1000     2        2       2         3   \n",
       "E7      1       27     1840        2    990     2        2       2         3   \n",
       "E8      1       28     1844        1   1000     1        2       2         1   \n",
       "\n",
       "    SPAN  REL-L  TYPE  \n",
       "E1     3      2     6  \n",
       "E2     3      2     6  \n",
       "E5     3      2     6  \n",
       "E7     2      2     6  \n",
       "E8     3      2     5  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dataset.isnull().values.any()\n",
    "# print('Before handling null values\\nThere are any null values ? Response: {}'.format(result))\n",
    "\n",
    "result = dataset.isnull().sum()\n",
    "# print('Number of null values for each predictor:\\n{}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '39.5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b94d2c2354fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcolumns_2_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ERECTED'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LENGTH'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LANES'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LOCATION'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns_2_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LOCATION'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LOCATION'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-b94d2c2354fa>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcolumns_2_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ERECTED'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LENGTH'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LANES'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LOCATION'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns_2_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LOCATION'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LOCATION'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '39.5'"
     ]
    }
   ],
   "source": [
    "# dataset[['LENGTH', 'SPAN']] = dataset[['LENGTH', 'SPAN']].replace(to_replace='?', value=None)\n",
    "dataset[['LENGTH', 'SPAN', 'LANES']] = dataset[['LENGTH', 'SPAN', 'LANES']].replace(to_replace='?', value=None, method='bfill')\n",
    "# dataset.head(5)\n",
    "# print(dataset['SPAN'].value_counts())\n",
    "# print(dataset['LENGTH'].value_counts())\n",
    "# print(dataset['LANES'].value_counts())\n",
    "\n",
    "# print(dataset.info())\n",
    "\n",
    "columns_2_map = ['ERECTED', 'LENGTH', 'LANES']\n",
    "for _, predictor in enumerate(columns_2_map):\n",
    "    dataset[predictor] = np.array(list(map(lambda x: int(x), dataset[predictor].values)))\n",
    "    \n",
    "dataset['LOCATION'] = np.array(list(map(lambda x: float(x), dataset['LOCATION'].values)))\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dataset.isnull().values.any()\n",
    "# print('After handling null values\\nThere are any null values ? Response: {}'.format(result))\n",
    "\n",
    "result = dataset.isnull().sum()\n",
    "# print('Number of null values for each predictor:\\n{}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_2_avoid = ['ERECTED', 'LENGTH', 'LOCATION']\n",
    "show_frequency_distribution_predictors(dataset, columns_2_avoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_result = dataset.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_heatmap(corr_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = dataset.columns\n",
    "target_col = 'T-OR-D'\n",
    "\n",
    "y = dataset[target_col].values\n",
    "print(dataset['T-OR-D'].value_counts())\n",
    "X = dataset.loc[:, dataset.columns != target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the features\n",
    "scaler_methods = ['minmax', 'standard', 'norm']\n",
    "scaler_method = 'minmax'\n",
    "rescaledX = preprocessing_data_rescaling(scaler_method, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = rescaledX.shape[1]\n",
    "pca = PCA(n_components=n_components)\n",
    "# pca = PCA(n_components=2)\n",
    "\n",
    "#X_pca = pca.fit_transform(X)\n",
    "pca = pca.fit(rescaledX)\n",
    "X_pca = pca.transform(rescaledX)\n",
    "    \n",
    "# fig = show_cum_variance_vs_components(pca, n_components)\n",
    "\n",
    "# py.sign_in('franec94', 'QbLNKpC0EZB0kol0aL2Z')\n",
    "# py.iplot(fig, filename='selecting-principal-components {}'.format(scaler_method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler_methods = ['minmax', 'standard', 'norm']\n",
    "scaler_methods = []\n",
    "for _, scaler_method in enumerate(scaler_methods):\n",
    "    rescaledX = preprocessing_data_rescaling(scaler_method, X)\n",
    "    \n",
    "    n_components = rescaledX.shape[1]\n",
    "    pca = PCA(n_components=n_components)\n",
    "    # pca = PCA(n_components=2)\n",
    "\n",
    "    #X_pca = pca.fit_transform(X)\n",
    "    pca = pca.fit(rescaledX)\n",
    "    X_pca = pca.transform(rescaledX)\n",
    "    \n",
    "    show_cum_variance_vs_components(pca, n_components)\n",
    "    fig = show_cum_variance_vs_components(pca, n_components)\n",
    "\n",
    "    # py.sign_in('franec94', 'QbLNKpC0EZB0kol0aL2Z')\n",
    "    py.iplot(fig, filename='selecting-principal-components {}'.format(scaler_method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principal_components = [pc for pc in '2,5,6,7,8,9,10'.split(',')]\n",
    "for _, pc in enumerate(principal_components):\n",
    "    n_components = int(pc)\n",
    "    \n",
    "    cum_var_exp_up_to_n_pcs = np.cumsum(pca.explained_variance_ratio_)[n_components-1]\n",
    "    print(f\"Cumulative varation explained up to {n_components} pcs = {cum_var_exp_up_to_n_pcs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgd_classifier_grid_search(rescaledX, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
